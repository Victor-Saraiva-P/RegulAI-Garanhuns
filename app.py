# app.py
import streamlit as st
from config import *  # Carrega vari√°veis e configura√ß√µes
from db import get_mongo_collection, load_documents
from embeddings import create_embeddings, split_documents, create_vectorstore
from llm import init_llm, rag_search
from pyngrok import ngrok
import os

# Configura√ß√£o do layout da p√°gina
st.set_page_config(page_title="RegulAI - Chatbot de Leis Municipais de Garanhuns", page_icon="üìú", layout="centered")

# Cria o t√∫nel do ngrok se necess√°rio (pode registrar no log)
if os.environ.get("NGROK_KEY"):
    public_url = ngrok.connect("http://localhost:8501", "http")
    st.write(f"T√∫nel do Ngrok criado: {public_url}")
    print(f"T√∫nel do ngrok ativo: {public_url}")

st.title("üìú RegulAI - Chatbot de Leis Municipais de Garanhuns üèõÔ∏è")
st.write("Pergunte sobre leis municipais e receba respostas baseadas nos textos legais!")

# Conectar ao MongoDB e carregar documentos
collection = get_mongo_collection()
test_doc = collection.find_one()
if not test_doc:
    st.error("Nenhum documento encontrado no MongoDB! Verifique a conex√£o e os dados.")
    st.stop()

raw_documents = load_documents(collection)
if not raw_documents:
    st.error("Nenhum documento v√°lido encontrado. Encerrando execu√ß√£o.")
    st.stop()

# Cria√ß√£o do vectorstore
embeddings = create_embeddings()
split_docs = split_documents(raw_documents)
if not split_docs:
    st.error("Nenhum peda√ßo de documento encontrado para FAISS. Verifique a extra√ß√£o de dados.")
    st.stop()
vector_store = create_vectorstore(split_docs, embeddings)

# Configura√ß√£o do LLM
llm = init_llm()

#Interface
st.subheader("üí¨ Fa√ßa sua pergunta:")
user_input = st.text_input("Digite sua pergunta:")
if user_input:
    with st.spinner("Buscando resposta..."):
        response = rag_search(user_input, vector_store, llm)
        content = response.content
        # Aqui, exiba somente a resposta limpa para o usu√°rio:
        st.text_area("Resposta:", content, height=200)
