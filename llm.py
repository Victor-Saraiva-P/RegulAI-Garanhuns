# llm.py
from dotenv import load_dotenv
import streamlit as st
from langchain_groq import ChatGroq
import os
import re

# Carrega as vari√°veis do arquivo .env
load_dotenv()
groqModel = os.environ.get('GROQ_MODEL')

def init_llm():
    print("Configurando LLM Groq...\n")
    llm = ChatGroq(model=groqModel)
    print("LLM configurado!")
    return llm


def rag_search(query: str, vector_store, llm):
    # Ajuste da regex:
    #  -> (\d{1,5}(?:\.\d{1,5})?/\d{4}) permite um ou mais pontos entre d√≠gitos
    #  -> Exemplo: "5.275/2024", "5275/2024", "12.345/2024", etc.
    lei_match = re.search(r"\b(\d{1,5}(?:\.\d{1,5})?/\d{4})\b", query)
    if lei_match:
        raw_numero = lei_match.group(1)  # Ex.: "5.275/2024"
        # Remove o(s) ponto(s) para coincidir com o que est√° salvo nos metadados ("5275/2024")
        numero_lei = raw_numero.replace(".", "")  # "5275/2024"
        print(f"Usu√°rio perguntou especificamente pela lei: {numero_lei}")

        # Filtra diretamente pelo metadado "numero_lei" == "5275/2024"
        matched_chunks = [
            doc for doc in vector_store.docstore._dict.values()
            if doc.metadata.get("numero_lei") == numero_lei
        ]

        if matched_chunks:
            print(f"Encontramos {len(matched_chunks)} chunks com esta lei.")
            relevant_docs = matched_chunks
        else:
            print("N√£o encontramos um match exato. Indo para busca vetorial...")
            relevant_docs = vector_store.similarity_search(query, k=5)
    else:
        # Se n√£o for uma pergunta espec√≠fica de lei, busca normal
        relevant_docs = vector_store.similarity_search(query, k=5)

    print(f"Documentos relevantes: {len(relevant_docs)}")
    for i, doc in enumerate(relevant_docs):
        metadata = doc.metadata
        print(f"üìú **Doc {i+1}** - Lei: {metadata.get('numero_lei')}")
        print(f"   Trecho: {doc.page_content[:200]}...\n")

    context = "\n".join([doc.page_content for doc in relevant_docs])
    prompt = (
        f"Voc√™ √© um especialista jur√≠dico encarregado de interpretar leis municipais de Garanhuns. "
        f"Seu objetivo √© fornecer respostas claras, precisas e diretas para perguntas sobre cada lei. "
        f"Sempre baseie suas respostas exclusivamente no texto da lei fornecida, sem suposi√ß√µes externas. "
        f"Se uma pergunta mencionar um n√∫mero de lei, verifique se ele est√° presente no texto antes de responder. "
        f"\n\nRegras para resposta:"
        f"\n- Se houver uma data mencionada, forne√ßa exatamente essa data sem alterar o formato."
        f"\n- Se houver um nome pr√≥prio, transcreva-o exatamente como aparece no texto da lei."
        f"\n- Se houver um valor financeiro, forne√ßa exatamente o valor sem reescrev√™-lo ou arredond√°-lo."
        f"\n- Se a informa√ß√£o n√£o estiver no texto, responda explicitamente que o dado n√£o foi encontrado."
        f"\n- Mantenha a resposta objetiva e sem repeti√ß√µes desnecess√°rias."
        f"\n- Se a pergunta tiver um formato Existe alguma lei? Sempre cite a lei."
        f"\n\n{context}\n\nPergunta: {query}\nResposta:"
)


    try:
        print("Enviando prompt para LLM...")
        response_ai_message = llm.invoke(prompt)  # retorna AIMessage
        response_text = response_ai_message.content  # converte para string
        print("Resposta gerada!")
    except Exception as e:
        response_text = f"Erro ao invocar LLM: {e}"

    return response_text  # agora sai como 'str'


